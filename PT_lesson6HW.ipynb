{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad69fff",
   "metadata": {},
   "source": [
    "Домашнее задание.\n",
    "1. Попробуйте обучить нейронную сеть с применением одномерных сверток для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
    "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fb74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4da7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 20\n",
    "num_classes = 1\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b94fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('twitter_data/train.csv')\n",
    "df_test = pd.read_csv('twitter_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b969ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca23c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stop-words in /home/boormistr/.local/lib/python3.10/site-packages (2018.7.23)\n",
      "Requirement already satisfied: pymorphy2 in /home/boormistr/.local/lib/python3.10/site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /home/boormistr/.local/lib/python3.10/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /home/boormistr/.local/lib/python3.10/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /home/boormistr/.local/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b5cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce59cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb70e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97b856b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in puncts)\n",
    "    txt = txt.lower()\n",
    "#     txt = re.sub(\"не\\s\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4552ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 22373/22373 [00:03<00:00, 7171.98it/s]\n",
      "100%|█████████████████████████████████████| 9589/9589 [00:01<00:00, 7606.74it/s]\n",
      "100%|███████████████████████████████████| 17197/17197 [00:02<00:00, 7691.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_train['tweet'] = df_train['tweet'].progress_apply(preprocess_text)\n",
    "df_val['tweet'] = df_val['tweet'].progress_apply(preprocess_text)\n",
    "df_test['tweet'] = df_test['tweet'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ab2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"tweet\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663beef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/boormistr/.local/lib/python3.10/site-packages (3.8)\n",
      "Requirement already satisfied: click in /home/boormistr/.local/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/boormistr/.local/lib/python3.10/site-packages (from nltk) (2022.3.2)\n",
      "Requirement already satisfied: tqdm in /home/boormistr/.local/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in /home/boormistr/.local/lib/python3.10/site-packages (from nltk) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32824eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/boormistr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['goodbye', 'safety', 'net', 'hello', 'selfemployment']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f417178",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582911ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
    "len(tokens_filtered_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c3402d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user', 'love', 'day', 'happy', 'amp', 'just', 'will', 'im', 'life', 'time']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85242c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 1,\n",
       " 'love': 2,\n",
       " 'day': 3,\n",
       " 'happy': 4,\n",
       " 'amp': 5,\n",
       " 'just': 6,\n",
       " 'will': 7,\n",
       " 'im': 8,\n",
       " 'life': 9,\n",
       " 'time': 10,\n",
       " 'u': 11,\n",
       " 'like': 12,\n",
       " 'today': 13,\n",
       " 'new': 14,\n",
       " 'now': 15,\n",
       " 'positive': 16,\n",
       " 'get': 17,\n",
       " 'thankful': 18,\n",
       " 'people': 19,\n",
       " 'good': 20,\n",
       " 'cant': 21,\n",
       " 'bihday': 22,\n",
       " 'one': 23,\n",
       " 'see': 24,\n",
       " 'can': 25,\n",
       " 'dont': 26,\n",
       " 'fathers': 27,\n",
       " 'want': 28,\n",
       " 'go': 29,\n",
       " 'smile': 30,\n",
       " 'healthy': 31,\n",
       " 'take': 32,\n",
       " 'got': 33,\n",
       " 'work': 34,\n",
       " 'weekend': 35,\n",
       " 'friday': 36,\n",
       " 'make': 37,\n",
       " 'fun': 38,\n",
       " 'best': 39,\n",
       " 'summer': 40,\n",
       " 'us': 41,\n",
       " 'great': 42,\n",
       " 'beautiful': 43,\n",
       " 'family': 44,\n",
       " 'way': 45,\n",
       " '2': 46,\n",
       " 'bull': 47,\n",
       " 'friends': 48,\n",
       " 'need': 49,\n",
       " 'first': 50,\n",
       " 'days': 51,\n",
       " 'music': 52,\n",
       " 'going': 53,\n",
       " 'really': 54,\n",
       " 'world': 55,\n",
       " 'back': 56,\n",
       " 'wait': 57,\n",
       " 'morning': 58,\n",
       " 'know': 59,\n",
       " 'sad': 60,\n",
       " 'tomorrow': 61,\n",
       " 'orlando': 62,\n",
       " 'never': 63,\n",
       " 'week': 64,\n",
       " 'fathersday': 65,\n",
       " 'happiness': 66,\n",
       " 'cute': 67,\n",
       " 'well': 68,\n",
       " 'think': 69,\n",
       " 'feel': 70,\n",
       " 'much': 71,\n",
       " 'trump': 72,\n",
       " 'blog': 73,\n",
       " 'model': 74,\n",
       " 'home': 75,\n",
       " 'even': 76,\n",
       " 'next': 77,\n",
       " 'affirmation': 78,\n",
       " 'sunday': 79,\n",
       " 'finally': 80,\n",
       " 'right': 81,\n",
       " 'night': 82,\n",
       " 'last': 83,\n",
       " 'youre': 84,\n",
       " 'amazing': 85,\n",
       " 'live': 86,\n",
       " 'come': 87,\n",
       " 'always': 88,\n",
       " 'still': 89,\n",
       " 'things': 90,\n",
       " 'year': 91,\n",
       " 'iam': 92,\n",
       " 'look': 93,\n",
       " 'girl': 94,\n",
       " 'find': 95,\n",
       " 'thanks': 96,\n",
       " 'thank': 97,\n",
       " 'little': 98,\n",
       " 'makes': 99,\n",
       " 'ready': 100,\n",
       " 'gold': 101,\n",
       " 'silver': 102,\n",
       " 'selfie': 103,\n",
       " 'altwaystoheal': 104,\n",
       " 'follow': 105,\n",
       " 'free': 106,\n",
       " 'na': 107,\n",
       " 'many': 108,\n",
       " 'via': 109,\n",
       " '4': 110,\n",
       " 'tonight': 111,\n",
       " 'dad': 112,\n",
       " 'looking': 113,\n",
       " 'bear': 114,\n",
       " 'man': 115,\n",
       " 'peace': 116,\n",
       " 'black': 117,\n",
       " 'another': 118,\n",
       " 'pay': 119,\n",
       " 'everyone': 120,\n",
       " 'climb': 121,\n",
       " 'show': 122,\n",
       " 'forex': 123,\n",
       " 'old': 124,\n",
       " 'hope': 125,\n",
       " 'blessed': 126,\n",
       " 'getting': 127,\n",
       " '1': 128,\n",
       " 'enjoy': 129,\n",
       " 'polar': 130,\n",
       " 'hate': 131,\n",
       " 'feeling': 132,\n",
       " 'god': 133,\n",
       " 'game': 134,\n",
       " 'sta': 135,\n",
       " 'stop': 136,\n",
       " 'say': 137,\n",
       " 'ever': 138,\n",
       " '2016': 139,\n",
       " 'watch': 140,\n",
       " 'help': 141,\n",
       " 'news': 142,\n",
       " 'whatever': 143,\n",
       " 'might': 144,\n",
       " 'food': 145,\n",
       " 'made': 146,\n",
       " 'excited': 147,\n",
       " 'white': 148,\n",
       " 'girls': 149,\n",
       " 'sun': 150,\n",
       " 'every': 151,\n",
       " 'thats': 152,\n",
       " 'saturday': 153,\n",
       " 'coming': 154,\n",
       " 'nothing': 155,\n",
       " 'dog': 156,\n",
       " 'keep': 157,\n",
       " 'funny': 158,\n",
       " 'city': 159,\n",
       " 'friend': 160,\n",
       " 'lol': 161,\n",
       " '3': 162,\n",
       " 'angry': 163,\n",
       " 'years': 164,\n",
       " 'guys': 165,\n",
       " 'let': 166,\n",
       " 'someone': 167,\n",
       " 'ive': 168,\n",
       " 'baby': 169,\n",
       " 'instagood': 170,\n",
       " 'may': 171,\n",
       " 'nice': 172,\n",
       " 'beach': 173,\n",
       " 'healing': 174,\n",
       " 'big': 175,\n",
       " 'found': 176,\n",
       " 'kids': 177,\n",
       " 'believe': 178,\n",
       " 'long': 179,\n",
       " 'soon': 180,\n",
       " 'america': 181,\n",
       " 'grateful': 182,\n",
       " 'school': 183,\n",
       " 'father': 184,\n",
       " 'proud': 185,\n",
       " 'around': 186,\n",
       " 'better': 187,\n",
       " 'hea': 188,\n",
       " 'true': 189,\n",
       " 'change': 190,\n",
       " 'video': 191,\n",
       " 'direct': 192,\n",
       " 'dominate': 193,\n",
       " 'watching': 194,\n",
       " 'two': 195,\n",
       " 'miss': 196,\n",
       " 'wedding': 197,\n",
       " 'done': 198,\n",
       " 'racing': 199,\n",
       " 'bing': 200,\n",
       " 'awesome': 201,\n",
       " 'away': 202,\n",
       " 'n': 203,\n",
       " 'lost': 204,\n",
       " 'please': 205,\n",
       " 'bong': 206,\n",
       " 'weeks': 207,\n",
       " 'bad': 208,\n",
       " 'yes': 209,\n",
       " 'quote': 210,\n",
       " 'women': 211,\n",
       " 'monday': 212,\n",
       " 'real': 213,\n",
       " 'thing': 214,\n",
       " 'end': 215,\n",
       " 'waiting': 216,\n",
       " 'face': 217,\n",
       " 'didnt': 218,\n",
       " 'motivation': 219,\n",
       " 'cool': 220,\n",
       " 'forward': 221,\n",
       " 'something': 222,\n",
       " 'give': 223,\n",
       " 'yeah': 224,\n",
       " 'wow': 225,\n",
       " 'libtard': 226,\n",
       " 'place': 227,\n",
       " 'without': 228,\n",
       " 'playing': 229,\n",
       " 'd': 230,\n",
       " 'hot': 231,\n",
       " 'sex': 232,\n",
       " 'rip': 233,\n",
       " 'holiday': 234,\n",
       " 'person': 235,\n",
       " 'book': 236,\n",
       " 'followme': 237,\n",
       " 'hard': 238,\n",
       " 'play': 239,\n",
       " 'team': 240,\n",
       " 'travel': 241,\n",
       " 'joy': 242,\n",
       " 'living': 243,\n",
       " 'wish': 244,\n",
       " 'oh': 245,\n",
       " 'twitter': 246,\n",
       " 'attack': 247,\n",
       " 'everything': 248,\n",
       " 'racist': 249,\n",
       " 'dads': 250,\n",
       " '5': 251,\n",
       " 'photooftheday': 252,\n",
       " 'gon': 253,\n",
       " 'check': 254,\n",
       " 'job': 255,\n",
       " 'health': 256,\n",
       " 'making': 257,\n",
       " 'tweets': 258,\n",
       " 'boy': 259,\n",
       " 'june': 260,\n",
       " 'ill': 261,\n",
       " 'sleep': 262,\n",
       " 'euro2016': 263,\n",
       " 'wont': 264,\n",
       " 'strong': 265,\n",
       " 'looks': 266,\n",
       " 'lovely': 267,\n",
       " 'hair': 268,\n",
       " 'buffalo': 269,\n",
       " 'shooting': 270,\n",
       " 'left': 271,\n",
       " 'r': 272,\n",
       " 'mindset': 273,\n",
       " 'politics': 274,\n",
       " 'sexy': 275,\n",
       " 'poetry': 276,\n",
       " 'tbt': 277,\n",
       " 'win': 278,\n",
       " 'house': 279,\n",
       " 'said': 280,\n",
       " 'london': 281,\n",
       " 'young': 282,\n",
       " 'yet': 283,\n",
       " 'ur': 284,\n",
       " 'already': 285,\n",
       " 'leave': 286,\n",
       " 'full': 287,\n",
       " 'doesnt': 288,\n",
       " 'listen': 289,\n",
       " 'fashion': 290,\n",
       " 'cold': 291,\n",
       " 'w': 292,\n",
       " 'pa': 293,\n",
       " 'try': 294,\n",
       " 'moment': 295,\n",
       " 'stay': 296,\n",
       " 'pretty': 297,\n",
       " 'guy': 298,\n",
       " 'body': 299,\n",
       " 'since': 300,\n",
       " 'working': 301,\n",
       " 'isnt': 302,\n",
       " 'mind': 303,\n",
       " 'fitness': 304,\n",
       " 'children': 305,\n",
       " 'lot': 306,\n",
       " 'song': 307,\n",
       " 'quotes': 308,\n",
       " 'couple': 309,\n",
       " '10': 310,\n",
       " 'loved': 311,\n",
       " 'depression': 312,\n",
       " 'lt3': 313,\n",
       " 'hear': 314,\n",
       " 'read': 315,\n",
       " 'porn': 316,\n",
       " 'success': 317,\n",
       " 'fuck': 318,\n",
       " 'use': 319,\n",
       " 'obama': 320,\n",
       " 'thought': 321,\n",
       " 'rest': 322,\n",
       " 'post': 323,\n",
       " 'must': 324,\n",
       " 'beauty': 325,\n",
       " 's': 326,\n",
       " 'mom': 327,\n",
       " 'enough': 328,\n",
       " 'x': 329,\n",
       " 'country': 330,\n",
       " 'hes': 331,\n",
       " 'says': 332,\n",
       " 'also': 333,\n",
       " 'season': 334,\n",
       " 'crazy': 335,\n",
       " 'gay': 336,\n",
       " 'simulation': 337,\n",
       " 'photo': 338,\n",
       " 'omg': 339,\n",
       " 'money': 340,\n",
       " 'dance': 341,\n",
       " 'buy': 342,\n",
       " 'super': 343,\n",
       " 'lets': 344,\n",
       " 'retweet': 345,\n",
       " 'flowers': 346,\n",
       " 'woman': 347,\n",
       " 'whats': 348,\n",
       " 'conference': 349,\n",
       " 'inspiration': 350,\n",
       " 'dead': 351,\n",
       " 'gorilla': 352,\n",
       " 'men': 353,\n",
       " 'shit': 354,\n",
       " 'thoughts': 355,\n",
       " 'words': 356,\n",
       " 'put': 357,\n",
       " 'call': 358,\n",
       " 'times': 359,\n",
       " 'till': 360,\n",
       " 'seeing': 361,\n",
       " 'comes': 362,\n",
       " 'hey': 363,\n",
       " 'thursday': 364,\n",
       " 'perfect': 365,\n",
       " 'nude': 366,\n",
       " 'shop': 367,\n",
       " '7': 368,\n",
       " 'hours': 369,\n",
       " 'cat': 370,\n",
       " 'dream': 371,\n",
       " 'movie': 372,\n",
       " 'liberal': 373,\n",
       " 'wonderful': 374,\n",
       " 'truth': 375,\n",
       " 'head': 376,\n",
       " 'relax': 377,\n",
       " 'environment': 378,\n",
       " 'month': 379,\n",
       " 'business': 380,\n",
       " 'coffee': 381,\n",
       " 'almost': 382,\n",
       " 'race': 383,\n",
       " 'tear': 384,\n",
       " 'together': 385,\n",
       " 'media': 386,\n",
       " 'yay': 387,\n",
       " 'story': 388,\n",
       " 'open': 389,\n",
       " 'care': 390,\n",
       " 'alone': 391,\n",
       " 'hour': 392,\n",
       " 'trying': 393,\n",
       " 'tell': 394,\n",
       " 'fans': 395,\n",
       " 'others': 396,\n",
       " 'sweet': 397,\n",
       " 'aww': 398,\n",
       " 'mood': 399,\n",
       " 'delete': 400,\n",
       " 'usa': 401,\n",
       " 'tweet': 402,\n",
       " 'far': 403,\n",
       " 'simulator': 404,\n",
       " 'adapt': 405,\n",
       " 'meet': 406,\n",
       " 'smiles': 407,\n",
       " 'toptags': 408,\n",
       " 'gift': 409,\n",
       " 'months': 410,\n",
       " 'sunshine': 411,\n",
       " 'run': 412,\n",
       " 'goes': 413,\n",
       " 'single': 414,\n",
       " 'share': 415,\n",
       " 'remember': 416,\n",
       " 'went': 417,\n",
       " 'sick': 418,\n",
       " 'wrong': 419,\n",
       " 'places': 420,\n",
       " 'gym': 421,\n",
       " 'gone': 422,\n",
       " 'boys': 423,\n",
       " 'useful': 424,\n",
       " 'sure': 425,\n",
       " 'vacation': 426,\n",
       " 'tired': 427,\n",
       " 'ppl': 428,\n",
       " 'anyone': 429,\n",
       " '1st': 430,\n",
       " 'talk': 431,\n",
       " 'followers': 432,\n",
       " 'anything': 433,\n",
       " 'anymore': 434,\n",
       " 'needs': 435,\n",
       " 'actually': 436,\n",
       " 'deletetweets': 437,\n",
       " 'nervous': 438,\n",
       " 'wednesday': 439,\n",
       " 'trip': 440,\n",
       " 'tickets': 441,\n",
       " 'lgbt': 442,\n",
       " 'blue': 443,\n",
       " 'victims': 444,\n",
       " 'daily': 445,\n",
       " 'join': 446,\n",
       " 'prayfororlando': 447,\n",
       " 'hardcore': 448,\n",
       " 'allahsoil': 449,\n",
       " 'special': 450,\n",
       " 'matter': 451,\n",
       " 'came': 452,\n",
       " 'sorry': 453,\n",
       " 'hello': 454,\n",
       " 'nature': 455,\n",
       " 'loving': 456,\n",
       " 'gun': 457,\n",
       " 'car': 458,\n",
       " 'yall': 459,\n",
       " 'lifestyle': 460,\n",
       " 'power': 461,\n",
       " 'kind': 462,\n",
       " 'celebrate': 463,\n",
       " 'tv': 464,\n",
       " 'cause': 465,\n",
       " 'uk': 466,\n",
       " 'happened': 467,\n",
       " 'running': 468,\n",
       " 'anxiety': 469,\n",
       " 'fact': 470,\n",
       " 'walk': 471,\n",
       " 'tuesday': 472,\n",
       " 'else': 473,\n",
       " 'gets': 474,\n",
       " 'bed': 475,\n",
       " 'high': 476,\n",
       " 'football': 477,\n",
       " 'forever': 478,\n",
       " 'son': 479,\n",
       " '6': 480,\n",
       " 'lunch': 481,\n",
       " 'suppo': 482,\n",
       " 'able': 483,\n",
       " 'todays': 484,\n",
       " 'death': 485,\n",
       " 'lucky': 486,\n",
       " 'later': 487,\n",
       " 'laugh': 488,\n",
       " 'word': 489,\n",
       " 'less': 490,\n",
       " 'child': 491,\n",
       " 'yesterday': 492,\n",
       " 'y': 493,\n",
       " 'saw': 494,\n",
       " 'instagram': 495,\n",
       " 'sjw': 496,\n",
       " 'seems': 497,\n",
       " 'hu': 498,\n",
       " 'green': 499,\n",
       " 'future': 500,\n",
       " 'whole': 501,\n",
       " 'empty': 502,\n",
       " 'favorite': 503,\n",
       " 'prayers': 504,\n",
       " 'social': 505,\n",
       " 'lives': 506,\n",
       " 'red': 507,\n",
       " 'history': 508,\n",
       " 'arrived': 509,\n",
       " 'goodmorning': 510,\n",
       " 'depressed': 511,\n",
       " 'families': 512,\n",
       " 'ago': 513,\n",
       " 'photography': 514,\n",
       " 'evening': 515,\n",
       " 'tgif': 516,\n",
       " 'bit': 517,\n",
       " 'killed': 518,\n",
       " 'wishing': 519,\n",
       " 'pic': 520,\n",
       " 'mean': 521,\n",
       " 'saying': 522,\n",
       " 'sunny': 523,\n",
       " 'fucking': 524,\n",
       " 'point': 525,\n",
       " 'guess': 526,\n",
       " 'everyday': 527,\n",
       " 'reached': 528,\n",
       " 'stas': 529,\n",
       " 'latest': 530,\n",
       " 'set': 531,\n",
       " 'safe': 532,\n",
       " 'birds': 533,\n",
       " 'break': 534,\n",
       " 'florida': 535,\n",
       " '20': 536,\n",
       " 'late': 537,\n",
       " 'act': 538,\n",
       " 'understand': 539,\n",
       " 'xxx': 540,\n",
       " 'vine': 541,\n",
       " 'become': 542,\n",
       " 'ok': 543,\n",
       " 'ass': 544,\n",
       " 'side': 545,\n",
       " 'staing': 546,\n",
       " 'used': 547,\n",
       " 'reason': 548,\n",
       " 'complete': 549,\n",
       " 'finished': 550,\n",
       " 'racism': 551,\n",
       " 'smh': 552,\n",
       " 'smiling': 553,\n",
       " 'b': 554,\n",
       " 'visit': 555,\n",
       " 'easy': 556,\n",
       " 'cry': 557,\n",
       " 'talking': 558,\n",
       " 'cantwait': 559,\n",
       " 'learn': 560,\n",
       " 'impoant': 561,\n",
       " 'daddy': 562,\n",
       " 'state': 563,\n",
       " 'havent': 564,\n",
       " 'shopping': 565,\n",
       " 'early': 566,\n",
       " '50': 567,\n",
       " 'gt': 568,\n",
       " 'pathetic': 569,\n",
       " 'dogs': 570,\n",
       " 'animals': 571,\n",
       " 'comments': 572,\n",
       " 'damn': 573,\n",
       " 'fan': 574,\n",
       " 'wan': 575,\n",
       " 'youtube': 576,\n",
       " 'date': 577,\n",
       " 'theyre': 578,\n",
       " 'orlandoshooting': 579,\n",
       " 'seen': 580,\n",
       " 'maybe': 581,\n",
       " 'app': 582,\n",
       " 'parents': 583,\n",
       " 'brexit': 584,\n",
       " 'reading': 585,\n",
       " 'mountains': 586,\n",
       " 'garden': 587,\n",
       " 'guns': 588,\n",
       " 'freedom': 589,\n",
       " 'sea': 590,\n",
       " 'homes': 591,\n",
       " 'leads': 592,\n",
       " 'style': 593,\n",
       " 'daughter': 594,\n",
       " 'happen': 595,\n",
       " 'nyc': 596,\n",
       " 'flag': 597,\n",
       " 'list': 598,\n",
       " 'dear': 599,\n",
       " 'education': 600,\n",
       " 'police': 601,\n",
       " 'despite': 602,\n",
       " 'photos': 603,\n",
       " 'episode': 604,\n",
       " 'send': 605,\n",
       " 'vs': 606,\n",
       " 'afternoon': 607,\n",
       " 'affirmations': 608,\n",
       " 'pray': 609,\n",
       " 'vote': 610,\n",
       " 'order': 611,\n",
       " 'happening': 612,\n",
       " 'wishes': 613,\n",
       " 'though': 614,\n",
       " 'design': 615,\n",
       " 'makeup': 616,\n",
       " '30': 617,\n",
       " 'england': 618,\n",
       " 'disney': 619,\n",
       " 'anniversary': 620,\n",
       " 'welcome': 621,\n",
       " 'group': 622,\n",
       " 'park': 623,\n",
       " 'update': 624,\n",
       " 'bring': 625,\n",
       " 'missing': 626,\n",
       " 'training': 627,\n",
       " 'community': 628,\n",
       " 'yo': 629,\n",
       " 'theres': 630,\n",
       " 'rain': 631,\n",
       " '12': 632,\n",
       " 'event': 633,\n",
       " 'tragedy': 634,\n",
       " 'president': 635,\n",
       " '8': 636,\n",
       " 'picoftheday': 637,\n",
       " 'yoga': 638,\n",
       " 'top': 639,\n",
       " 'won': 640,\n",
       " 'broken': 641,\n",
       " 'taking': 642,\n",
       " 'snapchat': 643,\n",
       " 'chill': 644,\n",
       " 'booked': 645,\n",
       " 'breakfast': 646,\n",
       " 'voice': 647,\n",
       " 'july': 648,\n",
       " 'forget': 649,\n",
       " 'couldnt': 650,\n",
       " 'water': 651,\n",
       " 'glad': 652,\n",
       " 'sometimes': 653,\n",
       " 'cake': 654,\n",
       " 'film': 655,\n",
       " 'goals': 656,\n",
       " 'dinner': 657,\n",
       " 'feels': 658,\n",
       " 'soul': 659,\n",
       " 'fresh': 660,\n",
       " 'bday': 661,\n",
       " 'boyfriend': 662,\n",
       " 'stuff': 663,\n",
       " 'heard': 664,\n",
       " 'target': 665,\n",
       " '2017': 666,\n",
       " 'choose': 667,\n",
       " 'save': 668,\n",
       " 'conce': 669,\n",
       " 'tragic': 670,\n",
       " 'hit': 671,\n",
       " 'americans': 672,\n",
       " 'slut': 673,\n",
       " 'sunset': 674,\n",
       " 'eyes': 675,\n",
       " 'lose': 676,\n",
       " 'course': 677,\n",
       " 'memories': 678,\n",
       " 'shows': 679,\n",
       " 'view': 680,\n",
       " 'violence': 681,\n",
       " 'wife': 682,\n",
       " 'vicinity': 683,\n",
       " 'cultureofdevelopment': 684,\n",
       " 'organizations': 685,\n",
       " 'half': 686,\n",
       " 'rock': 687,\n",
       " 'name': 688,\n",
       " 'final': 689,\n",
       " 'control': 690,\n",
       " 'feelings': 691,\n",
       " 'lighttherapy': 692,\n",
       " 'workout': 693,\n",
       " 'local': 694,\n",
       " 'naughty': 695,\n",
       " 'nasty': 696,\n",
       " 'wanted': 697,\n",
       " 'wants': 698,\n",
       " '2nd': 699,\n",
       " 'worst': 700,\n",
       " 'rooster': 701,\n",
       " 'ta': 702,\n",
       " 'line': 703,\n",
       " 'bc': 704,\n",
       " 'close': 705,\n",
       " 'bought': 706,\n",
       " 'heres': 707,\n",
       " 'picture': 708,\n",
       " 'mad': 709,\n",
       " 'called': 710,\n",
       " 'color': 711,\n",
       " 'gorgeous': 712,\n",
       " 'fridayfeeling': 713,\n",
       " 'ones': 714,\n",
       " 'india': 715,\n",
       " 'ahead': 716,\n",
       " 'kill': 717,\n",
       " 'vast': 718,\n",
       " 'expanse': 719,\n",
       " 'dreams': 720,\n",
       " 'moments': 721,\n",
       " 'mother': 722,\n",
       " 'actor': 723,\n",
       " 'phone': 724,\n",
       " 'stomping': 725,\n",
       " 'sister': 726,\n",
       " 'respect': 727,\n",
       " 'heal': 728,\n",
       " 'brother': 729,\n",
       " 'moving': 730,\n",
       " 'agree': 731,\n",
       " 'leaving': 732,\n",
       " 'shy': 733,\n",
       " 'class': 734,\n",
       " 'spos': 735,\n",
       " 'mass': 736,\n",
       " 'due': 737,\n",
       " 'survive': 738,\n",
       " 'thankyou': 739,\n",
       " 'ramadan': 740,\n",
       " 'ask': 741,\n",
       " 'enjoying': 742,\n",
       " 'chase': 743,\n",
       " 'husband': 744,\n",
       " 'beer': 745,\n",
       " 'shot': 746,\n",
       " 'mine': 747,\n",
       " 'officially': 748,\n",
       " 'adventure': 749,\n",
       " 'war': 750,\n",
       " 'simple': 751,\n",
       " 'woh': 752,\n",
       " 'die': 753,\n",
       " 'bless': 754,\n",
       " 'online': 755,\n",
       " 'disappointed': 756,\n",
       " 'kinky': 757,\n",
       " 'wet': 758,\n",
       " 'horny': 759,\n",
       " 'club': 760,\n",
       " 'behind': 761,\n",
       " 'eat': 762,\n",
       " 'blonde': 763,\n",
       " 'friendship': 764,\n",
       " 'camp': 765,\n",
       " 'udtapunjab': 766,\n",
       " 'hill': 767,\n",
       " 'meeting': 768,\n",
       " 'university': 769,\n",
       " 'gop': 770,\n",
       " 'york': 771,\n",
       " 'least': 772,\n",
       " 'shes': 773,\n",
       " 'facebook': 774,\n",
       " 'reality': 775,\n",
       " 'service': 776,\n",
       " 'using': 777,\n",
       " 'light': 778,\n",
       " 'weve': 779,\n",
       " 'fear': 780,\n",
       " 'truly': 781,\n",
       " 'leadership': 782,\n",
       " 'needed': 783,\n",
       " 'hell': 784,\n",
       " 'puppy': 785,\n",
       " 'exciting': 786,\n",
       " 'national': 787,\n",
       " 'dj': 788,\n",
       " 'reach': 789,\n",
       " 'turn': 790,\n",
       " 'suppoers': 791,\n",
       " '9': 792,\n",
       " 'gbp': 793,\n",
       " 'along': 794,\n",
       " 'wonder': 795,\n",
       " 'move': 796,\n",
       " 'teen': 797,\n",
       " 'pain': 798,\n",
       " 'france': 799,\n",
       " 'thinking': 800,\n",
       " 'busy': 801,\n",
       " 'crying': 802,\n",
       " 'present': 803,\n",
       " 'writing': 804,\n",
       " 'ride': 805,\n",
       " 'congrats': 806,\n",
       " 'kid': 807,\n",
       " 'heabroken': 808,\n",
       " 'dark': 809,\n",
       " 'human': 810,\n",
       " 'different': 811,\n",
       " 'three': 812,\n",
       " 'youve': 813,\n",
       " 'official': 814,\n",
       " 'walking': 815,\n",
       " 'street': 816,\n",
       " 'queen': 817,\n",
       " '100': 818,\n",
       " 'hands': 819,\n",
       " 'fantastic': 820,\n",
       " 'fit': 821,\n",
       " 'ways': 822,\n",
       " 'pizza': 823,\n",
       " 'seriously': 824,\n",
       " 'emotions': 825,\n",
       " 'king': 826,\n",
       " 'poor': 827,\n",
       " 'instead': 828,\n",
       " 'past': 829,\n",
       " 'speak': 830,\n",
       " 'joke': 831,\n",
       " 'scared': 832,\n",
       " 'bitch': 833,\n",
       " 'aint': 834,\n",
       " 'videos': 835,\n",
       " 'tech': 836,\n",
       " 'means': 837,\n",
       " 'donald': 838,\n",
       " 'pool': 839,\n",
       " 'source': 840,\n",
       " 'e32016': 841,\n",
       " 'whos': 842,\n",
       " 'realize': 843,\n",
       " 'loves': 844,\n",
       " 'wake': 845,\n",
       " 'pop': 846,\n",
       " 'gave': 847,\n",
       " 'lawofattraction': 848,\n",
       " 'takes': 849,\n",
       " 'sky': 850,\n",
       " 'tips': 851,\n",
       " 'islam': 852,\n",
       " 'finding': 853,\n",
       " 'la': 854,\n",
       " 'star': 855,\n",
       " 'weather': 856,\n",
       " 'staff': 857,\n",
       " 'office': 858,\n",
       " 'vegas': 859,\n",
       " 'literally': 860,\n",
       " 'sense': 861,\n",
       " 'nba': 862,\n",
       " 'dancing': 863,\n",
       " 'self': 864,\n",
       " 'giving': 865,\n",
       " 'staed': 866,\n",
       " 'experience': 867,\n",
       " 'babies': 868,\n",
       " 'p': 869,\n",
       " 'vegan': 870,\n",
       " 'content': 871,\n",
       " 'spend': 872,\n",
       " 'series': 873,\n",
       " 'confused': 874,\n",
       " 'snapshot': 875,\n",
       " 'small': 876,\n",
       " 'congratulations': 877,\n",
       " 'hatred': 878,\n",
       " 'account': 879,\n",
       " 'trending': 880,\n",
       " 'american': 881,\n",
       " 'jobs': 882,\n",
       " 'task': 883,\n",
       " 'fly': 884,\n",
       " 'especially': 885,\n",
       " 'met': 886,\n",
       " 'students': 887,\n",
       " 'trust': 888,\n",
       " 'luck': 889,\n",
       " 'yummy': 890,\n",
       " 'apple': 891,\n",
       " 'lots': 892,\n",
       " 'lover': 893,\n",
       " 'inside': 894,\n",
       " 'fall': 895,\n",
       " 'l': 896,\n",
       " 'campaign': 897,\n",
       " 'deserve': 898,\n",
       " 'dress': 899,\n",
       " 'died': 900,\n",
       " 'blur': 901,\n",
       " 'listening': 902,\n",
       " 'minutes': 903,\n",
       " 'stand': 904,\n",
       " 'college': 905,\n",
       " 'pussy': 906,\n",
       " '15': 907,\n",
       " 'oitnb': 908,\n",
       " 'hungry': 909,\n",
       " 'lonely': 910,\n",
       " 'happier': 911,\n",
       " 'hillary': 912,\n",
       " 'tears': 913,\n",
       " 'games': 914,\n",
       " 'horrible': 915,\n",
       " 'countdown': 916,\n",
       " 't': 917,\n",
       " 'wild': 918,\n",
       " 'punjab': 919,\n",
       " 'cats': 920,\n",
       " 'sale': 921,\n",
       " 'muslim': 922,\n",
       " 'nofilter': 923,\n",
       " 'probably': 924,\n",
       " 'drink': 925,\n",
       " 'stupid': 926,\n",
       " 'newyork': 927,\n",
       " 'opening': 928,\n",
       " 'pride': 929,\n",
       " 'train': 930,\n",
       " 'like4like': 931,\n",
       " 'nbafinals': 932,\n",
       " '3d': 933,\n",
       " 'rather': 934,\n",
       " 'road': 935,\n",
       " 'energy': 936,\n",
       " 'gif': 937,\n",
       " 'idea': 938,\n",
       " 'ness': 939,\n",
       " 'political': 940,\n",
       " 'flower': 941,\n",
       " 'australia': 942,\n",
       " 'oil': 943,\n",
       " 'leakage': 944,\n",
       " 'celebrating': 945,\n",
       " 'wtf': 946,\n",
       " 'absolutely': 947,\n",
       " 'web': 948,\n",
       " 'internet': 949,\n",
       " 'stage': 950,\n",
       " 'ripchristina': 951,\n",
       " 'given': 952,\n",
       " 'number': 953,\n",
       " 'arent': 954,\n",
       " 'customer': 955,\n",
       " 'blogger': 956,\n",
       " 'huge': 957,\n",
       " 'germany': 958,\n",
       " 'v': 959,\n",
       " 'step': 960,\n",
       " 'action': 961,\n",
       " 'problem': 962,\n",
       " 'flight': 963,\n",
       " 'id': 964,\n",
       " 'loss': 965,\n",
       " 'low': 966,\n",
       " 'e3': 967,\n",
       " 'spring': 968,\n",
       " 'naked': 969,\n",
       " 'pink': 970,\n",
       " 'hero': 971,\n",
       " 'missed': 972,\n",
       " 'lady': 973,\n",
       " 'exactly': 974,\n",
       " 'either': 975,\n",
       " 'eah': 976,\n",
       " 'fire': 977,\n",
       " 'sign': 978,\n",
       " 'married': 979,\n",
       " 'pictures': 980,\n",
       " 'calling': 981,\n",
       " 'received': 982,\n",
       " 'nails': 983,\n",
       " 'spain': 984,\n",
       " 'disgusting': 985,\n",
       " 'melancholy': 986,\n",
       " 'chance': 987,\n",
       " 'united': 988,\n",
       " 'e': 989,\n",
       " 'sho': 990,\n",
       " 'choice': 991,\n",
       " 'watched': 992,\n",
       " 'states': 993,\n",
       " 'knows': 994,\n",
       " 'definitely': 995,\n",
       " 'aist': 996,\n",
       " 'fight': 997,\n",
       " 'shame': 998,\n",
       " 'lord': 999,\n",
       " 'broke': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc3907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return result[-maxlen:] + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce369c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"tweet\"]])\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"tweet\"]])\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"tweet\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97dfcfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bec99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size=2000, embedding_dim = 128, out_channel = 128,\n",
    "                 num_classes = 1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv_1 = nn.Conv1d(embedding_dim, out_channel, kernel_size=2)\n",
    "        self.conv_2 = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_1 = nn.Linear(out_channel, out_channel//2)\n",
    "        self.linear_2 = nn.Linear(out_channel//2, num_classes)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        output = self.embedding(x)        \n",
    "        output = output.permute(0, 2, 1)\n",
    "        output = self.conv_1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.pool(output)\n",
    "        \n",
    "        output = self.conv_2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.pool(output)\n",
    "        \n",
    "        output = torch.max(output, axis=2).values\n",
    "        output = self.linear_1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear_2(output)\n",
    "        output = F.sigmoid(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8239a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feea0488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1602"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bae06fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataWrapper(x_train, df_train['label'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DataWrapper(x_val, df_val['label'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c5de042",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(vocab_size=max_words)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f0170b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(2000, 128)\n",
      "  (conv_1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
      "  (conv_2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      "  (linear_1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear_2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Parameters:  346497\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('Parameters: ', sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "756601de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c48a5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boormistr/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]. Step: [44/44]. Loss: 0.116, Acc: 0.91025. Test loss:  0.009.             Test acc:  0.93326\n",
      "Epoch [2/30]. Step: [44/44]. Loss: 0.148, Acc: 0.94408. Test loss:  0.004.             Test acc:  0.94890\n",
      "Epoch [3/30]. Step: [44/44]. Loss: 0.110, Acc: 0.96335. Test loss:  0.106.             Test acc:  0.95067\n",
      "Epoch [4/30]. Step: [44/44]. Loss: 0.063, Acc: 0.97720. Test loss:  0.389.             Test acc:  0.94452\n",
      "Epoch [5/30]. Step: [44/44]. Loss: 0.023, Acc: 0.98512. Test loss:  0.000.             Test acc:  0.94713\n",
      "Epoch [6/30]. Step: [44/44]. Loss: 0.019, Acc: 0.98918. Test loss:  0.240.             Test acc:  0.94191\n",
      "Epoch [7/30]. Step: [44/44]. Loss: 0.011, Acc: 0.99146. Test loss:  0.015.             Test acc:  0.94827\n",
      "Epoch [8/30]. Step: [44/44]. Loss: 0.017, Acc: 0.99303. Test loss:  0.004.             Test acc:  0.94619\n",
      "Epoch [9/30]. Step: [44/44]. Loss: 0.023, Acc: 0.99294. Test loss:  0.063.             Test acc:  0.93878\n",
      "Epoch [10/30]. Step: [44/44]. Loss: 0.021, Acc: 0.99468. Test loss:  0.001.             Test acc:  0.94567\n",
      "Epoch [11/30]. Step: [44/44]. Loss: 0.009, Acc: 0.99566. Test loss:  2.743.             Test acc:  0.95057\n",
      "Epoch [12/30]. Step: [44/44]. Loss: 0.010, Acc: 0.99611. Test loss:  0.000.             Test acc:  0.94024\n",
      "Epoch [13/30]. Step: [44/44]. Loss: 0.031, Acc: 0.99508. Test loss:  0.000.             Test acc:  0.94765\n",
      "Epoch [14/30]. Step: [44/44]. Loss: 0.018, Acc: 0.99446. Test loss:  0.000.             Test acc:  0.94608\n",
      "Epoch [15/30]. Step: [44/44]. Loss: 0.002, Acc: 0.99705. Test loss:  0.000.             Test acc:  0.95130\n",
      "Epoch [16/30]. Step: [44/44]. Loss: 0.008, Acc: 0.99701. Test loss:  0.025.             Test acc:  0.94588\n",
      "Epoch [17/30]. Step: [44/44]. Loss: 0.001, Acc: 0.99705. Test loss:  0.000.             Test acc:  0.94984\n",
      "Epoch [18/30]. Step: [44/44]. Loss: 0.003, Acc: 0.99669. Test loss:  0.004.             Test acc:  0.94827\n",
      "Epoch [19/30]. Step: [44/44]. Loss: 0.042, Acc: 0.99540. Test loss:  3.248.             Test acc:  0.94233\n",
      "Epoch [20/30]. Step: [44/44]. Loss: 0.023, Acc: 0.99401. Test loss:  0.020.             Test acc:  0.94515\n",
      "Epoch [21/30]. Step: [44/44]. Loss: 0.037, Acc: 0.99687. Test loss:  2.127.             Test acc:  0.94786\n",
      "Epoch [22/30]. Step: [44/44]. Loss: 0.004, Acc: 0.99696. Test loss:  0.010.             Test acc:  0.94327\n",
      "Epoch [23/30]. Step: [44/44]. Loss: 0.011, Acc: 0.99741. Test loss:  0.053.             Test acc:  0.95026\n",
      "Epoch [24/30]. Step: [44/44]. Loss: 0.007, Acc: 0.99607. Test loss:  0.000.             Test acc:  0.94911\n",
      "Epoch [25/30]. Step: [44/44]. Loss: 0.010, Acc: 0.99692. Test loss:  0.000.             Test acc:  0.95088\n",
      "Epoch [26/30]. Step: [44/44]. Loss: 0.010, Acc: 0.99629. Test loss:  0.001.             Test acc:  0.94994\n",
      "Epoch [27/30]. Step: [44/44]. Loss: 0.007, Acc: 0.99754. Test loss:  0.000.             Test acc:  0.94661\n",
      "Epoch [28/30]. Step: [44/44]. Loss: 0.011, Acc: 0.99616. Test loss:  0.000.             Test acc:  0.94932\n",
      "Epoch [29/30]. Step: [44/44]. Loss: 0.007, Acc: 0.99656. Test loss:  0.000.             Test acc:  0.94932\n",
      "Epoch [30/30]. Step: [44/44]. Loss: 0.004, Acc: 0.99750. Test loss:  0.000.             Test acc:  0.94942\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    "th = 0.5\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "    \n",
    "    model.eval()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "          f'Step: [{i + 1}/{len(train_loader)}]. '\\\n",
    "          f'Loss: {loss:.3f}, ' \\\n",
    "          f'Acc: {running_right / running_items:.5f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "    \n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(val_loader):\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = model(data[0].to(device))\n",
    "        \n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1,1))\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "        \n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss: .3f}. \\\n",
    "            Test acc: {test_running_right / test_running_total: .5f}')\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4914633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
